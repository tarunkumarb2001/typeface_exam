Crawling a website means it is a bot in which it contains information about that website like data,images etc…It automatically downloads the requested information and it will be available for user needs.
When it comes to crawling we can use some online tools for crawling a website or we can write a code for that to crawl the website.Based upon my knowledge  if we want to crawl the data first we want to send http request to the web page then it responds weather it can send data or not then if yes we can move further  and try to access the data in that website to download the data we can use code to download that data .if you are familiar with python or java  language it contain so many libraries and by using that we can collect the data from the website.


Python frameworks like Beautifulsoup and requests are used to crawl a website.